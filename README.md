# ðŸš€ Live Object Detection App (ARKit + Vision)

An augmented reality iOS app that identifies real-world objects in real-time using ARKit, Vision, and CoreML.

## ðŸ“± Features

- ðŸŽ¥ Real-time object detection with iPhone camera
- ðŸ§  Powered by CoreML and Vision Framework
- ðŸ“¦ Displays detected object names in AR space using RealityKit
- ðŸŒ Uses MobileNetV2 for on-device object classification

## ðŸ› ï¸ Tech Stack

- `Swift`
- `ARKit`
- `RealityKit`
- `CoreML`
- `Vision`

## ðŸ§‘â€ðŸ’» How to Run

1. **Clone the Repository**

```bash
git clone https://github.com/yourusername/live-object-detection-ar.git
cd live-object-detection-ar
```

2. **Open the Xcode Project**

```bash
open LiveObjectDetection.xcodeproj
```

3. **Ensure Setup**

- âœ… Xcode 15 or later
- âœ… iOS 16+ deployment target
- âœ… Real device with A12 chip or later
- âœ… Add `MobileNetV2.mlmodel` to your project

4. **Run on a Real Device**

- ARKit and Vision require camera and neural engine â€“ simulator will not work.


## ðŸ“· Sample Output

> "Detected: Coffee Mug (0.93)" appears floating in front of the object in AR space.

## âœ¨ Future Work

- Add sound feedback
- Save detection history
- Toggle between object models
